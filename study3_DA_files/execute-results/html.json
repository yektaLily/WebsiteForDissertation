{
  "hash": "32355622cd2692b45e65053e154d2c11",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Device Divide\" \nauthor: \"Yekta Amirkhalili\"\ndate: \"today\"\nformat: \n  html: \n    code-fold: false\n    code-tools: false\n    self-contained: false\n    execute:\n      eval: true \n      echo: true\n      warning: false\n      message: false\n      error: false\n      results: 'asis'\n    #css: style.css\nbibliography: references.bib\ncsl: apa.csl\n---\n\n<!-- CSS CHANGES -->\n<style>\n.quarto-title h1.title {\n  font-size: 1.5rem; \n}\n\nh2{\n    font-size: 1.2rem;\n    background-color:rgba(128, 170, 156, 0.48);\n}\n\n.future-idea-box {\n  border: 2px solid var(--quarto-hl-header-color, #86bdab); /* Uses Quarto header color variable or fallback */\n  border-radius: 8px;\n  padding: 1em;\n  margin: 1em 0;\n  background: #f9f9fc;\n}\n.future-idea-title {\n  font-weight: bold;\n  color: var(--quarto-hl-header-color,rgb(111, 172, 152));\n  margin-bottom: 0.5em;\n  font-size: 1.1em;\n}\n\n.variable-card {\n  border: 2px solid #447099;           /* Choose your border color */\n  background: #f5f8fa;                 /* Light background */\n  border-radius: 8px;\n  padding: 1.2em 1.5em;\n  margin: 1em 0;\n  box-shadow: 0 2px 8px rgba(68,112,153,0.05);\n  max-width: 500px;\n}\n\n</style>\n<!-- CSS CHANGES -->\n\n\n## Data Analysis \nIn this project, I focused on analyzing how mental health relates to mobile banking adoption.\nI used data from the Canadian Internet Use Survey 2022, which includes questions about various digital habits, and demographics.\nYou can find the dataset [here](https://abacus.library.ubc.ca/dataset.xhtml?persistentId=hdl:11272.1/AB2/68AZGA). \n\nFor this project, I conducted a comparative analysis of two logistic regression models one for smartphone users, refered to from here on out and PHONE users and one for smart wearable users, refered to as WEAR users. \nSince the sampling methodology involved clustering by provinces, I considered robust standard errors for reporting the results. \nTo build the models, I needed to conceptualize technology, in this case, m-banking adoption. \nSince I'm considering two different devices, I needed factors that impact m-banking decisions for both devices to be able to compare them.\n\nThis was very challenging because there are not many m-banking using smartwearable device studies! \nSo, I broadened the scope to consider any technology adoption.\nThis is ok to do as long as the factors are not specific to a niche context. \nThe variables are Trust, Perceived Security, Perceived Value, and few demographic varaibles such as Age, Gender, Education and Income. \n\nHere are my hypotheses: \n\n* H1: The association between Trust and m-banking adoption is the same for smartphone and smart wearable users\n* H2: The association between Perceived security and m-banking adoption is the same for smartphone and smart wearable users.\n* H3: The association between Perceived value (measured by time savings) and m-banking adoption is the same for smartphone and smart wearable users.\n    * H4.1 : The association between Age and m-banking adoption is the same for smartphone and smart wearable users.\n    * H4.2 : The association between Gender and m-banking adoption is the same for smartphone and smart wearable users.\n    * H4.3 : The association between Education and m-banking adoption is the same for smartphone and smart wearable users.\n    * H4.4 : The association between Income and m-banking adoption is the same for smartphone and smart wearable users.\n\n\n### Importing Libraries \nNote that not all libraries may be utilized. \nThe most important ones are `dplyr`, `lme4`, `tidyr`, `lavaan`, `ggplot2`, `psych`, `corrr`, `haven`, `poLCA` and any related libraries to these. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrr)\nlibrary(psych)\nlibrary(lavaan)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(haven)\nlibrary(rempsyc)\nlibrary(broom)\nlibrary(report)\nlibrary(effectsize)\nlibrary(aod)\nlibrary(readr)\nlibrary(forcats)\nlibrary(ggcorrplot)\nlibrary(caret)\nlibrary(knitr)\nlibrary(ROCR)\nlibrary(jtools)\nlibrary(xtable)\nlibrary(glmnet)\nlibrary(ggpubr)\nlibrary(lme4)\nlibrary(nlme)\nlibrary(weights)\nlibrary(miscTools)\nlibrary(systemfit)\nlibrary(multcomp)\nrequire(ggplot2)\nrequire(GGally)\nrequire(reshape2)\nrequire(lattice)\nlibrary(HLMdiag)\nlibrary(margins)\nlibrary(performance)\nlibrary(ggnewscale)\nlibrary(ggeffects)\nlibrary(ggeffects)\nlibrary(marginaleffects)\nlibrary(effects)\nlibrary(margins)\nlibrary(modelr)\nlibrary(plm)\nlibrary(effectsize)\nlibrary(aod)\nlibrary(readr)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(glmnet)\nlibrary(ggpubr)\nlibrary(foreign)\nlibrary(AER)\nlibrary(lme4)\nlibrary(formatR)\nlibrary(pglm)\nlibrary(acqr)\nlibrary(lmtest)\nlibrary(poLCA)\nlibrary(mirt)\nlibrary(texreg)\nlibrary(gt)\n```\n:::\n\n\n### Introducing the CIUS 2022\n\nThis dataset is very similar to CIUS 2020 from study 2. \nI first started by reading the entire PUMF file available.  \nThis gives you information on how the survey was set up, why, and how things were measured. \nThen, I looked at the individual survey questions to see the available data, and how they were measured. \nIn general, questions are measured numerically were answeres follow as such:\n\n> Yes : 1\n> No : 2   \n> Valid Skip: 6\n> Don't Know: 7\n> Refusal: 8\n> Not Stated: 9 \n\nOf course this differs question-by-question as some questions have other answer categories and some questions (which were note used in my study) asked for numerical input from the participants (like how much did you spend online last year).\nTo help readers understand the data, I will include the question exactly as it appears in the CIUS 2022 PUMF Data Dictionary with corresponding answer choices and codes. \nThese will be in a blue-bordered box, and will include the Variable name (on the PUMF file), Concept, Question Body and Answers. \nThen I will show you in R code how I've re-coded and used the question as a model variable. \nThe Variables I need are as follows: \n\n* Mobile banking adoption (`MBANK`)\n* Province (`PRVNC`)\n* Age Group (`AGE`)\n* Gender (`SEX`)\n* Education Level (`EDU`) \n* Income Quintile (`INCOME`) \n* User Type (`USR_TYP`) - based on the following \n  * Smartphone User (`isSmartPhone`)\n  * Smartwearable User (`isSmartWear`)\n* Saved Time Because of m-banking (`EFF_TIME`)\n* Perceived Security (`PSEC`) - based on the following \n  * Security measure: restricting access to location (`SEC_RES_LOC`)\n  * Security measure: restricting access to data (`SEC_RES_DAT`)\n  * Security check: checked security of a website (`SEC_ACC_WEBSEC`)\n  * Security check: changed privacy settings (`SEC_ACC_CHNGPRV`)\n  * Security feature: security questions (`SECOPT_QS`)\n  * Security feature: partner login (`SECOPT_PL`)\n  * Security feature: two factor authentication (`SECOPT_2FA`)\n  * Security feature: biometric (`SECOPT_BIO`)\n  * Security feature: password manager (`SECOPT_PAS`)\n* Trust in Banks (`TRST_BANK`)\n* Family Relation Satisfaction (`FAMSAT`)\n\nThe data is available in various formats. \nTo avoid data loss, I decided to use the `.dta` format (SAS file).\nYou need the `haven` package to read SAS files. \nThis is how you'd read a SAS file: \n\n::: {.cell}\n\n```{.r .cell-code}\ndata_2022 <- read_dta(\"data/00_CIUS2022.dta\")\nds00 <- data_2022\ndim(ds00)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25118   342\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds00\n```\n:::\n\n\n\n### Constructing Model Variables \n\n- Renaming variables \n- Cleaning data: delete the skips and such for both categorical and numerical variables \n- Verifying that our measure of latent constructs are strong enough \n\n\n### Demographic Variables\nSince these are not direct questions but information retrieved from other sources (such as postal codes for province), some of them do not have Skips/Don't Know/Refusal/Not Stated answers. \nIf they have, I have added those to the cards. \n\n**Province, Age, Sex, Education, Income**:\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** PROVINCE\n:::\n::: {.column width=\"50%\"}\n**Concept:** PROVINCE\n:::\n:::\n\n**Question Text/Note:**  \nInformation derived using postal codes.\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Newfoundland and Labrador | 10 | \n| Prince Edward Island | 11 | \n| Nova Scotia | 12 | \n| New Brunswick | 13 | \n| Quebec | 24 | \n| Ontario | 35 | \n| Manitoba | 46 | \n| Saskatchewan | 47 | \n| Alberta | 48 | \n| British Columbia | 59 | \n| Valid skip | 96 |\n| Don't know | 97 |\n| Refusal | 98 | \n| Not stated | 99 |\n:::::\n\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** AGE_GRP\n:::\n::: {.column width=\"50%\"}\n**Concept:** Age Groups - Derived variable\n:::\n:::\n\n**Question Text/Note:**  \nInformation derived from age of persons in household.\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| 15 to 24 years | 01 |\n| 25 to 34 years | 02 |\n| 35 to 44 years | 03 |\n| 45 to 54 years | 04 |\n| 55 to 64 years | 05 |\n| 65 years and over | 06 |\n| Valid skip | 96 |\n| Don't know | 97 |\n| Refusal | 98 |\n| Not stated | 99 |\n:::::\n\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** GENDER\n:::\n::: {.column width=\"50%\"}\n**Concept:** Gender - Derived variable\n:::\n:::\n\n**Question Text/Note:**  \n\nRefers to current gender which may be different from sex assigned at birth and may be different from what is indicated on legal documents. For data quality and confidentiality\nreasons, and because of the small population being measured, the dissemination of data according to ’Non binary’ Gender is not possible for this statistical program. So, this release uses a gender variable with only two categories. This variable is derived by looking at a large number of demographic characteristics from the respondent, it allows us to disseminate data on Gender that is reliable and unbiased.\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Male | 1 | \n| Female | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** EMP\n:::\n::: {.column width=\"50%\"}\n**Concept:** Employment status - Derived variable\n:::\n:::\n\n**Question Text/Note:**  \n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Employed | 1 | \n| Not employed | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** EDU\n:::\n::: {.column width=\"50%\"}\n**Concept:** Highest certificate - Derived variable\n:::\n:::\n\n**Question Text/Note:**  \n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| High school or less | 1 | \n| Some post-secondary (incl. univ certificate) | 2 | \n| University degree | 3 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** HINCQUIN\n:::\n::: {.column width=\"50%\"}\n**Concept:** Census family income quintile - Derived variable\n:::\n:::\n\n**Question Text/Note:**  \n\nInformation derived using HINC. \nIn order to obtain equal weighted counts in each category, cases with incomes equal to the category cutoffs were randomly assigned to one of the two categories on either side of the cutoff.\n\n**Source** Annual Income Estimates for Census Families and Individuals (T1 Family File)\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Quintile 1 - $\\leq$ $42,256  | 1 |\n| Quintile 2 - $42,257 - $72,366  | 2 |\n| Quintile 3 - $72,367 - $107,480  | 3 |\n| Quintile 4 - $107,481 - $163,750  | 4 |\n| Quintile 5 - > $163,750  | 5 |\n| Valid skip  | 6 |\n| Don't know  | 7 |\n| Refusal  | 8 |\n| Not stated  | 9 |\n:::::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds0 %>% mutate(\n    \n    ID = as.factor(pumfid),\n    PRVNC = case_when(\n        province == 10 ~ \"NL\",\n        province == 11 ~ \"PEI\",\n        province == 12 ~ \"NS\",\n        province == 13 ~ \"NB\",\n        province == 24 ~ \"QC\",\n        province == 35 ~ \"ON\",\n        province == 46 ~ \"MB\",\n        province == 47 ~ \"SK\",\n        province == 48 ~ \"AB\",\n        province == 59 ~ \"BC\",\n        .default = \"default\"\n    ),\n\n    AGE = ifelse(\n        AGE_GRP > 10,\n        0,\n        AGE_GRP\n    ),\n    \n    SEX = case_when(\n        gender == 1 ~ 0, #\"M\",\n        gender == 2 ~ 1, #\"F\",\n        .default = -1 #\"default\" #other\n    ),\n    \n    EMP = case_when(\n        emp == 1 ~ 1,\n        emp == 2 ~ 0, #no\n        .default = -1\n    ),\n    \n    EDU = case_when(\n        edu == 1 ~ 1, #\"Highschool\",\n        edu == 2 ~ 2, #\"College\",\n        edu == 3 ~ 3, #\"University\",\n        .default = 0 #\"default\"\n    ),\n    \n    INCOME = case_when(\n        hincquin == 1 ~ 1, #\"Q1\",\n        hincquin == 2 ~ 2, #\"Q2\",\n        hincquin == 3 ~ 3, #\"Q3\",\n        hincquin == 4 ~ 4, #\"Q4\",\n        hincquin == 5 ~ 5, #\"Q5\",\n        .default = 0 #\"default\"\n    )\n)\n```\n:::\n\n\n### Other Model Variables \n\n**Devices and Mbanking**:\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** DV_010A\n:::\n::: {.column width=\"50%\"}\n**Concept:** Devices used\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past three months, what devices did you use to access the Internet?\nDid you use:\n*A smartphone*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** DV_010G\n:::\n::: {.column width=\"50%\"}\n**Concept:** Devices used\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past three months, what devices did you use to access the Internet?\nDid you use:\n*Internet-connected wearable smart devices*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\nCIUS's Microdata User Guide has a section (section 4. Concepts and Defintions) but it does not include a definition for Internet connected smart wearable devices. \nUsing the internet, some examples of these smart wearable devices are: \n\n* Smart glasses \n* Smart watch \n* Fitness Trackers \n* Smart Shirt \n* GPS devices (SGPS/GPRS Body Control)\n* Bluetooth Key Trackers \n* Smart Belts \n* Smart Rings \n* Smart Bracelets \n* Virtual Reality devices \n* Smart clothing \n\nMore specific to Canada, according to [Ingenium.ca](https://ingenium.ca/scitech/en/exhibitions/wearable-tech/), the top devices are:\n\n* Smartwatches (Apple Watch, Samsung Galaxy Watch and Fitbits)\n* Fitness Trackers (Fitbit, Garmin)\n* Health Monitoring Devices (continuous glucose monitors)\n\nAlso true from CIUS 2020's report: \n\n> In addition, 14% of Canadians used Internet-connected wearable smart devices, such as a smart watch, Fit Bit or glucose monitoring device \n\nIt's safe to assume that smart wearables most definitely include smartwatches. \n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** UI_050D\n:::\n::: {.column width=\"50%\"}\n**Concept:** Activities related to other online activities\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past three months, which of the following other online activities, have you done over the Internet?\nHave you:\n*Conducted online banking*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds0 %>% mutate(\n    SMRTPHN = case_when(\n        DV_010A == 1 ~ 1,\n        DV_010A == 2 ~ 0,\n        .default = -1\n    ),\n    \n    SMRTWTCH = case_when(\n        DV_010G == 1 ~ 1,\n        DV_010G == 2 ~ 0,\n        .default = -1\n    ),\n    \n    MBANK = case_when(\n        UI_050D == 1 ~ 1,\n        UI_050D == 2 ~ 0,\n        .default = -1\n    )\n)\n```\n:::\n\n\n**Time Saving Effects**\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** UI_110E\n:::\n::: {.column width=\"50%\"}\n**Concept:** Effects of the use of online activities\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did your use of online activities have any of the following effects?\nDid it:\n*Save you time*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds0 %>% mutate(\n    EFF_TIME = case_when(\n        UI_110E == 1 ~ 1,\n        UI_110E == 2 ~ 0,\n        .default = -1\n    )\n)\n```\n:::\n\n\nAnd since the online activity I'm considering is mobile banking, this would be about mobile banking (more on this in my paper, as it's not entirely true - this is a limitation).\n\n**Security**\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_010A\n:::\n::: {.column width=\"50%\"}\n**Concept:** Activities carried out to manage access to personal data\n:::\n:::\n\n**Question Text/Note:**  \nHave you carried out any of the following to manage access to your personal data over the Internet during the past 12 months?\nHave you:\n*Restricted or refused access to your geographical location*\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_010B\n:::\n::: {.column width=\"50%\"}\n**Concept:** Activities carried out to manage access to personal data\n:::\n:::\n\n**Question Text/Note:**  \nHave you carried out any of the following to manage access to your personal data over the Internet during the past 12 months?\nHave you:\n*Refused allowing the use of personal data for advertising purposes*\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_010C\n:::\n::: {.column width=\"50%\"}\n**Concept:** Activities carried out to manage access to personal data\n:::\n:::\n\n**Question Text/Note:**  \nHave you carried out any of the following to manage access to your personal data over the Internet during the past 12 months?\nHave you:\n*Checked that the website where you provided personal data was secure*\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_010D\n:::\n::: {.column width=\"50%\"}\n**Concept:** Activities carried out to manage access to personal data\n:::\n:::\n\n**Question Text/Note:**  \nHave you carried out any of the following to manage access to your personal data over the Internet during the past 12 months?\nHave you:\n*Changed the privacy settings on accounts or apps*\n\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n**Security Measures - Setting Up**\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_020A\n:::\n::: {.column width=\"50%\"}\n**Concept:** Verified identity over the Internet\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did you enable any of the following optional security features to verify your identity when accessing accounts or applications over the Internet?\nDid you enable:\n*Answers to personalized security questions*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_020B\n:::\n::: {.column width=\"50%\"}\n**Concept:** Verified identity over the Internet\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did you enable any of the following optional security features to verify your identity when accessing accounts or applications over the Internet?\nDid you enable:\n*Partner login*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_020C\n:::\n::: {.column width=\"50%\"}\n**Concept:** Verified identity over the Internet\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did you enable any of the following optional security features to verify your identity when accessing accounts or applications over the Internet?\nDid you enable:\n*Two-factor authentication or two-step verification*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_020D\n:::\n::: {.column width=\"50%\"}\n**Concept:** Verified identity over the Internet\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did you enable any of the following optional security features to verify your identity when accessing accounts or applications over the Internet?\nDid you enable:\n*Biometric security features for online functions*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_020E\n:::\n::: {.column width=\"50%\"}\n**Concept:** Verified identity over the Internet\n:::\n:::\n\n**Question Text/Note:**  \nDuring the past 12 months, did you enable any of the following optional security features to verify your identity when accessing accounts or applications over the Internet?\nDid you enable:\n*Password manager program*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| Yes | 1 | \n| No | 2 | \n| Valid skip | 6 |\n| Don't know | 7 |\n| Refusal | 8 | \n| Not stated | 9 |\n:::::\n  \n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds0 %>% mutate(\n    SEC_RES_LOC = case_when(\n        SP_010A == 1 ~ 1,\n        SP_010A == 2 ~ 0,\n        .default = -1\n    ),\n\n    SEC_RES_DAT = case_when(\n        SP_010B == 1 ~ 1,\n        SP_010B == 2 ~ 0,\n        .default = -1\n    ),\n\n    SEC_ACC_WEBSEC = case_when(\n        SP_010C == 1 ~ 1,\n        SP_010C == 2 ~ 0,\n        .default = -1\n    ),\n    \n    SEC_ACC_CHNGPRV = case_when(\n        SP_010D == 1 ~ 1,\n        SP_010D == 2 ~ 0,\n        .default = -1\n    ),\n\n    SECOPT_QS = case_when(\n        SP_020A == 1 ~ 1,\n        SP_020A == 2 ~ 0,\n        .default = -1\n    ),\n    \n    \n    SECOPT_PL = case_when(\n        SP_020B == 1 ~ 1,\n        SP_020B == 2 ~ 0,\n        .default = -1\n    ),\n\n    SECOPT_2FA = case_when(\n        SP_020C == 1 ~ 1,\n        SP_020C == 2 ~ 0,\n        .default = -1\n    ),\n    \n    SECOPT_BIO = case_when(\n        SP_020D == 1 ~ 1,\n        SP_020D == 2 ~ 0,\n        .default = -1\n    ),\n    \n    SECOPT_PAS = case_when(\n        SP_020E == 1 ~ 1,\n        SP_020E == 2 ~ 0,\n        .default = -1\n    )\n)\n```\n:::\n\n\n**Trust In Banks/Financial Institutes**\n\n::::: {.variable-card}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n**Variable Name:** SP_040B\n:::\n::: {.column width=\"50%\"}\n**Concept:** Personal information - Trust in organizations\n:::\n:::\n\n**Question Text/Note:**  \nIn general, on a scale from 1 to 5 where 1 means \"cannot be trusted at all\" and 5 means \"can be trusted completely\", to what extent do you trust the following organizations with your personal information?\nWould you say:\n*b. Banking or other financial institutions*\n\n|**Answer Categories**|**Code**| \n|---------------------|--------| \n| 1 - Cannot be trusted at all  | 1 |\n| 2  | 2 |\n| 3 - Neutral  | 3 |\n| 4  | 4 |\n| 5 - Can be trusted completely  | 5 |\n| Valid skip  | 6 |\n| Don't know  | 7 |\n| Refusal  | 8 |\n| Not stated  | 9 |\n\n:::::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds0 <- ds0 %>% mutate(\n    TRST_BANK = case_when(\n        SP_040B == 1 ~ 1, #cannot be trusted \n        SP_040B == 2 ~ 2, \n        SP_040B == 3 ~ 3, #neutral\n        SP_040B == 4 ~ 4,\n        SP_040B == 5 ~ 5, #totally trusted \n        .default = 0\n    )\n)\n```\n:::\n\n\nSelecting only the useful columns: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_useful <- ds0 %>% dplyr::select(wtpg:TRST_BANK)\n```\n:::\n\n\nI have to make sure that online banking is actually capturing mobile banking, so, people must be smartphone users: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_mobilebank <- ds_useful %>% filter(SMRTPHN == 1)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(ds_mobilebank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20136    22\n```\n\n\n:::\n:::\n\n\nLooking at the data, \n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(ds_mobilebank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 20,136\nColumns: 22\n$ wtpg            <dbl> 1264.0837, 3413.0468, 585.5445, 378.8767, 4060.0513, 7…\n$ ID              <fct> 100001, 100002, 100004, 100005, 100007, 100008, 100009…\n$ PRVNC           <chr> \"QC\", \"MB\", \"QC\", \"SK\", \"QC\", \"QC\", \"AB\", \"ON\", \"SK\", …\n$ AGE             <dbl> 3, 1, 5, 4, 2, 4, 6, 3, 3, 6, 2, 3, 4, 5, 4, 5, 5, 4, …\n$ SEX             <dbl> 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, …\n$ EMP             <dbl> 1, 0, 0, 1, 1, 1, 0, 1, -1, 0, 1, 1, 1, -1, 1, 1, 0, 1…\n$ EDU             <dbl> 3, 1, 2, 1, 2, 2, 2, 2, 0, 3, 3, 3, 3, 2, 1, 3, 3, 2, …\n$ INCOME          <dbl> 2, 2, 4, 2, 2, 5, 5, 5, 5, 4, 3, 4, 3, 3, 1, 4, 2, 4, …\n$ SMRTPHN         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ SMRTWTCH        <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MBANK           <dbl> 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ EFF_TIME        <dbl> 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, …\n$ SEC_RES_LOC     <dbl> 1, 0, 1, 0, 0, 0, 0, 1, -1, 0, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ SEC_RES_DAT     <dbl> 1, 0, 1, 0, 0, 0, 1, 0, -1, 0, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ SEC_ACC_WEBSEC  <dbl> 1, 0, 0, 0, 1, 0, 1, 0, -1, 0, 0, 0, 0, 0, 1, 1, 0, 0,…\n$ SEC_ACC_CHNGPRV <dbl> 1, 0, 1, 0, 0, 0, 1, 0, -1, 0, 1, 0, 1, 0, 1, 1, 0, 0,…\n$ SECOPT_QS       <dbl> 1, 0, 1, 0, 0, 0, 1, 1, -1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ SECOPT_PL       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 1, 0, 0, 1,…\n$ SECOPT_2FA      <dbl> 1, 0, 1, 0, 0, 0, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1,…\n$ SECOPT_BIO      <dbl> 0, 0, 0, 0, 1, 0, 1, 0, -1, 0, 1, 1, 0, 0, 1, 1, 0, 1,…\n$ SECOPT_PAS      <dbl> 1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0, 0, 1, 1, 0, 0,…\n$ TRST_BANK       <dbl> 3, 3, 3, 3, 3, 4, 3, 3, 0, 5, 4, 4, 3, 3, 3, 4, 4, 5, …\n```\n\n\n:::\n:::\n\n\nI see there are some $-1$ values and some values that don't make sense. \nDrop these. \nThe data is large enough such that 100 rows won't affect the analysis. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncleaned_ds <- ds_mobilebank %>% filter(\n    !is.na(AGE) & \n    SEX != -1 & \n    EDU != -1 & \n    EDU != 0 & \n    INCOME != -1 & \n    SMRTWTCH != -1 & \n    MBANK != -1 & \n    EFF_TIME != -1 & \n    SEC_RES_LOC != -1 & \n    SEC_RES_DAT != -1 & \n    SEC_ACC_WEBSEC != -1 & \n    SEC_ACC_CHNGPRV != -1 & \n    SECOPT_QS != -1 & \n    SECOPT_PL != -1 & \n    SECOPT_2FA != -1 & \n    SECOPT_BIO != -1 & \n    SECOPT_PAS != -1 & \n    TRST_BANK != -1 & \n    TRST_BANK != 0 \n    )\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(cleaned_ds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 18552    22\n```\n\n\n:::\n:::\n\n\nSaving this in a database called `wrk_ds` (working database):\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds <- cleaned_ds\n```\n:::\n\n\n## Perceived Security Measurement \nSince there is no perceived security measure I need to define it as a latent variable. \nIn the CIUS2022, there's no single, direct question asking:\n\n> How secure do you think mobile banking is?\n\nThat means \"Perceived Security\" isn't directly measured.\nHowever, we have multiple related questions (e.g., about data protection, privacy, security measures, etc.).\nThese indirect items are observable variables that reflect an unobservable (latent) concept: the user's overall perception of security.\n\nI use Confirmatory Factor Analysis (CFA) to test if these items really reflect one underlying factor, i.e., `PSEC`.\nThis increases measurement reliability. \nHere are the steps of CFA: \n\n**Step 1. Reliability Check**\n\nUsing Cronbach's Alpha, I check the internal consistency of the items. \nUsually, if $\\alpha > 0.7$, the items are measuring the same idea.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalph <- psych::alpha(wrk_ds[, c(\"SEC_RES_LOC\", \"SEC_RES_DAT\", \"SEC_ACC_WEBSEC\", \"SEC_ACC_CHNGPRV\", \n            \"SECOPT_QS\", \"SECOPT_PL\", \"SECOPT_2FA\", \n            \"SECOPT_BIO\", \"SECOPT_PAS\")])\n\nalph$total$raw_alpha\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8103267\n```\n\n\n:::\n:::\n\n\nWhich means the measurement is strong. \n\n**Step 2. Exploratory Factor Check**\n\nWith Parallel Analysis, I can decide how many factors to extract. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfa.parallel(wrk_ds[, c(\"SEC_RES_LOC\", \"SEC_RES_DAT\", \"SEC_ACC_WEBSEC\", \"SEC_ACC_CHNGPRV\", \n                       \"SECOPT_QS\", \"SECOPT_PL\", \"SECOPT_2FA\", \"SECOPT_BIO\", \"SECOPT_PAS\")], \n            fa = \"fa\")\n```\n:::\n\n\n![](images/screeplot.png)\n\n*Note: the eighenvalue on the y-axis is basically the varaince each factor explains*\n\nFrom a parallel scree plot, you should look for an \"elbow\" - this is where the curve changes direction, which looks like 2 here. \nParallel analysis suggests 2 separate factors.\nThat is, it could be that the factors I'm looking at are actually describing two different latent ideas:\n\n* Maybe security measures like questions, 2FA, biometrics \n* and security concerns overall, like not allowing access to location or data \n\nHowever, I still think they're basically both perceptions of security of an app. \nYou only do these things if you think the app is not secure or you're worried about security. \nSo, I'll keep these factors and decide if something should be combined or dropped from CFA results. \n\n**Step 3. Confirmatory Factor Analysis**\n\nThe mathematical model is \n$$\nX_i = \\lambda_i PSEC_i + \\epsilon_i\n$$\nWhere $X_i$'s are the observed variables, $\\lambda_i$ is factor loading of varaible $i$ and $\\epsilon$ is the error term. \nThis is as if asking \"can all 9 items be explained by 1 variable (`PSEC`)?\".\nI'm adding covariances to improve the model fit. \nHow did I decide how to add covariates (this notation $\\sim\\sim$)? \nTrial and error, tbh! \nBut also, mostly intuitive. \nThe questions about security measures like setting up 2FA, questions, biometrics, password managers and partner login are all kind of related (to the same idea of \"setting up and using security measures/features\").\nThey have the same context on CIUS questionnairs, too. \nSimilarly, the data and location access are kind of about the same idea: they're both restrictions on what is shared about you. \nLastly, changing privacy and checking a website's security is are both activities that are not part of security features. \nThere's no set up, and all websites and apps have to allow you to be able to change privacy settings and you can check any website. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nf1 <- '\n    f =~ SEC_RES_LOC + SEC_RES_DAT + SEC_ACC_WEBSEC + SEC_ACC_CHNGPRV + SECOPT_QS + SECOPT_PL + SECOPT_2FA + SECOPT_BIO + SECOPT_PAS\n    \n    # Adding covariances between related error terms (based on modindices)\n    SEC_RES_LOC\t~~\tSEC_RES_DAT\n\n    SECOPT_QS\t~~\tSECOPT_2FA \n    SECOPT_BIO\t~~\tSECOPT_PAS \n    SEC_ACC_WEBSEC\t~~\tSEC_ACC_CHNGPRV\t \n    SECOPT_QS\t~~\tSECOPT_PL\t\n'\ncompatibility_fac <- cfa(f1, data = wrk_ds, std.lv = TRUE)\n\nsummary(compatibility_fac, fit.measures = TRUE, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6.16 ended normally after 43 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n  Number of observations                         18552\n\nModel Test User Model:\n                                                      \n  Test statistic                              1328.000\n  Degrees of freedom                                22\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                             42055.218\n  Degrees of freedom                                36\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969\n  Tucker-Lewis Index (TLI)                       0.949\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -93888.613\n  Loglikelihood unrestricted model (H1)     -93224.613\n                                                      \n  Akaike (AIC)                              187823.227\n  Bayesian (BIC)                            188003.278\n  Sample-size adjusted Bayesian (SABIC)     187930.185\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.057\n  90 Percent confidence interval - lower         0.054\n  90 Percent confidence interval - upper         0.059\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.034\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f =~                                                                  \n    SEC_RES_LOC       0.274    0.004   74.861    0.000    0.274    0.581\n    SEC_RES_DAT       0.300    0.004   82.428    0.000    0.300    0.627\n    SEC_ACC_WEBSEC    0.281    0.004   70.897    0.000    0.281    0.564\n    SEC_ACC_CHNGPR    0.336    0.004   88.679    0.000    0.336    0.673\n    SECOPT_QS         0.258    0.004   65.258    0.000    0.258    0.523\n    SECOPT_PL         0.219    0.004   58.760    0.000    0.219    0.466\n    SECOPT_2FA        0.275    0.003   81.371    0.000    0.275    0.620\n    SECOPT_BIO        0.221    0.004   58.219    0.000    0.221    0.462\n    SECOPT_PAS        0.217    0.004   55.881    0.000    0.217    0.446\n\nCovariances:\n                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .SEC_RES_LOC ~~                                                         \n   .SEC_RES_DAT        0.059    0.001   40.627    0.000    0.059    0.414\n .SECOPT_QS ~~                                                           \n   .SECOPT_2FA         0.026    0.001   19.955    0.000    0.026    0.181\n .SECOPT_BIO ~~                                                          \n   .SECOPT_PAS         0.033    0.002   21.891    0.000    0.033    0.180\n .SEC_ACC_WEBSEC ~~                                                      \n   .SEC_ACC_CHNGPR     0.020    0.002   13.119    0.000    0.020    0.131\n .SECOPT_QS ~~                                                           \n   .SECOPT_PL          0.021    0.001   14.773    0.000    0.021    0.119\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .SEC_RES_LOC       0.147    0.002   80.302    0.000    0.147    0.663\n   .SEC_RES_DAT       0.139    0.002   76.666    0.000    0.139    0.607\n   .SEC_ACC_WEBSEC    0.169    0.002   79.760    0.000    0.169    0.682\n   .SEC_ACC_CHNGPR    0.137    0.002   70.015    0.000    0.137    0.547\n   .SECOPT_QS         0.176    0.002   83.349    0.000    0.176    0.726\n   .SECOPT_PL         0.173    0.002   88.126    0.000    0.173    0.783\n   .SECOPT_2FA        0.121    0.002   77.426    0.000    0.121    0.615\n   .SECOPT_BIO        0.180    0.002   88.309    0.000    0.180    0.787\n   .SECOPT_PAS        0.190    0.002   88.964    0.000    0.190    0.802\n    f                 1.000                               1.000    1.000\n```\n\n\n:::\n:::\n\n\n\nFor CFA, this is how you'd interpret the results: \n\n|Metric| Desired Threshold|\tDescription|\n|------|------------------|------------|\n|CFI (Comparative Fit Index)|\t> 0.90 | Higher is better fit|\n|TLI (Tucker-Lewis Index)|\t> 0.90\t| Higher is better fit|\n|RMSEA (Root Mean Square Error of Approx.)|\t< 0.08 or ideally < 0.05| Lower is better (error)|\n|SRMR (Standardized Root Mean Residual)| < 0.08\t| Lower is better|\n\nThe more of these \"checkboxes\" your summary output checks, the better the fit for the factor. \nFactor loadings are about how strongly each factor represents/reflects the latent factor. \nThe higher the values the better (and significant).\n\nMy results are excellent for now, but, it's also good to check for residuals and correlations:\n\n**Step 4. Are Items Correlated?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodindices(compatibility_fac, sort = TRUE, minimum.value = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               lhs op             rhs      mi    epc sepc.lv sepc.all sepc.nox\n53       SECOPT_PL ~~      SECOPT_PAS 169.942  0.018   0.018    0.100    0.100\n54      SECOPT_2FA ~~      SECOPT_BIO 128.215  0.014   0.014    0.092    0.092\n51       SECOPT_PL ~~      SECOPT_2FA 115.978  0.014   0.014    0.096    0.096\n32     SEC_RES_DAT ~~  SEC_ACC_WEBSEC 111.173  0.012   0.012    0.081    0.081\n52       SECOPT_PL ~~      SECOPT_BIO  92.814  0.013   0.013    0.074    0.074\n46 SEC_ACC_CHNGPRV ~~      SECOPT_2FA  86.313 -0.012  -0.012   -0.090   -0.090\n33     SEC_RES_DAT ~~ SEC_ACC_CHNGPRV  82.720  0.011   0.011    0.077    0.077\n26     SEC_RES_LOC ~~ SEC_ACC_CHNGPRV  63.660  0.009   0.009    0.064    0.064\n28     SEC_RES_LOC ~~       SECOPT_PL  58.695 -0.009  -0.009   -0.055   -0.055\n45 SEC_ACC_CHNGPRV ~~       SECOPT_PL  56.901 -0.010  -0.010   -0.066   -0.066\n30     SEC_RES_LOC ~~      SECOPT_BIO  46.796 -0.008  -0.008   -0.048   -0.048\n41  SEC_ACC_WEBSEC ~~      SECOPT_2FA  38.361 -0.008  -0.008   -0.054   -0.054\n35     SEC_RES_DAT ~~       SECOPT_PL  35.212 -0.007  -0.007   -0.044   -0.044\n55      SECOPT_2FA ~~      SECOPT_PAS  32.752  0.007   0.007    0.046    0.046\n36     SEC_RES_DAT ~~      SECOPT_2FA  30.066 -0.006  -0.006   -0.043   -0.043\n31     SEC_RES_LOC ~~      SECOPT_PAS  25.153 -0.006  -0.006   -0.035   -0.035\n38     SEC_RES_DAT ~~      SECOPT_PAS  23.792 -0.006  -0.006   -0.035   -0.035\n42  SEC_ACC_WEBSEC ~~      SECOPT_BIO  22.575 -0.007  -0.007   -0.038   -0.038\n43  SEC_ACC_WEBSEC ~~      SECOPT_PAS  19.748 -0.006  -0.006   -0.035   -0.035\n37     SEC_RES_DAT ~~      SECOPT_BIO  18.991 -0.005  -0.005   -0.032   -0.032\n34     SEC_RES_DAT ~~       SECOPT_QS  12.791 -0.004  -0.004   -0.026   -0.026\n50       SECOPT_QS ~~      SECOPT_PAS  11.720  0.005   0.005    0.026    0.026\n```\n\n\n:::\n:::\n\n\nA few modification indeces are quite large, indicating these variables are highly correlated. \nSo, it's a good idea to add a covariance for them to the model. \nHowever, adding too much risks complicating the model and potentially overfitting. \nSince my analysis so far shows strong fit (above 90% CFI), I stop here. \nHowever, there's room for improvement! \n\n**Step 5. Check Sample-sized control RMSEA**\n\nSince my sample size is quite large, the RMSEA is affected. \nIn fact, all the metrics (especially $\\chi^2$) are. \nSo, I'll calculate the sample-sized normalized RMSEA:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitmeasures(compatibility_fac, \"rmsea\") / sqrt(18552)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nrmsea \n    0 \n```\n\n\n:::\n:::\n\n\nAnd check the reliability of the model: \n\n::: {.cell}\n\n```{.r .cell-code}\n# reliability(compatibility_fac) --- 82%\n```\n:::\n\n\n**Step 6. Subgroup Analysis**\n\nBefore we define `PSEC`, I have to figure out how many different categories I want. \nThe smallest would be 2: high and low. \nI want to check for unobserved subgroups/subclasses. \nThis is called *Latent Class Analysis (LCA)*.\nSince the values for the items had 0's in them, I have to add 1's to everything (required for `poLCA`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds[, c(\"SEC_RES_LOC\", \"SEC_RES_DAT\", \"SEC_ACC_WEBSEC\", \"SEC_ACC_CHNGPRV\",\n           \"SECOPT_QS\", \"SECOPT_PL\", \"SECOPT_2FA\", \"SECOPT_BIO\", \"SECOPT_PAS\")] <- \n  wrk_ds[, c(\"SEC_RES_LOC\", \"SEC_RES_DAT\", \"SEC_ACC_WEBSEC\", \"SEC_ACC_CHNGPRV\",\n             \"SECOPT_QS\", \"SECOPT_PL\", \"SECOPT_2FA\", \"SECOPT_BIO\", \"SECOPT_PAS\")] + 1\n\nform <- cbind(SEC_RES_LOC, SEC_RES_DAT, SEC_ACC_WEBSEC, SEC_ACC_CHNGPRV,\n            SECOPT_QS, SECOPT_PL, SECOPT_2FA, SECOPT_BIO, SECOPT_PAS) ~ 1\n\n# Run LCA with 2 latent classes\nlca_model <- poLCA(form, data = wrk_ds, nclass = 2, maxiter = 5000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$SEC_RES_LOC\n           Pr(1)  Pr(2)\nclass 1:  0.6822 0.3178\nclass 2:  0.1056 0.8944\n\n$SEC_RES_DAT\n           Pr(1)  Pr(2)\nclass 1:  0.7381 0.2619\nclass 2:  0.1067 0.8933\n\n$SEC_ACC_WEBSEC\n           Pr(1)  Pr(2)\nclass 1:  0.8797 0.1203\nclass 2:  0.3350 0.6650\n\n$SEC_ACC_CHNGPRV\n           Pr(1)  Pr(2)\nclass 1:  0.8775 0.1225\nclass 2:  0.2212 0.7788\n\n$SECOPT_QS\n           Pr(1)  Pr(2)\nclass 1:  0.7263 0.2737\nclass 2:  0.2124 0.7876\n\n$SECOPT_PL\n           Pr(1)  Pr(2)\nclass 1:  0.9084 0.0916\nclass 2:  0.5167 0.4833\n\n$SECOPT_2FA\n           Pr(1)  Pr(2)\nclass 1:  0.5936 0.4064\nclass 2:  0.0585 0.9415\n\n$SECOPT_BIO\n           Pr(1)  Pr(2)\nclass 1:  0.8906 0.1094\nclass 2:  0.4840 0.5160\n\n$SECOPT_PAS\n           Pr(1)  Pr(2)\nclass 1:  0.8515 0.1485\nclass 2:  0.4569 0.5431\n\nEstimated class population shares \n 0.3951 0.6049 \n \nPredicted class memberships (by modal posterior prob.) \n 0.3843 0.6157 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 18552 \nnumber of estimated parameters: 19 \nresidual degrees of freedom: 492 \nmaximum log-likelihood: -93737.84 \n \nAIC(2): 187513.7\nBIC(2): 187662.4\nG^2(2): 9189.15 (Likelihood ratio/deviance statistic) \nX^2(2): 17134.16 (Chi-square goodness of fit) \n \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(lca_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               Length Class      Mode   \nllik               1  -none-     numeric\nattempts           1  -none-     numeric\nprobs.start        9  -none-     list   \nprobs              9  -none-     list   \nprobs.se           9  -none-     list   \nP.se               2  -none-     numeric\nposterior      37104  -none-     numeric\npredclass      18552  -none-     numeric\nP                  2  -none-     numeric\nnumiter            1  -none-     numeric\nprobs.start.ok     1  -none-     logical\ncoeff              1  -none-     logical\ncoeff.se           1  -none-     logical\ncoeff.V            1  -none-     logical\neflag              1  -none-     logical\nnpar               1  -none-     numeric\naic                1  -none-     numeric\nbic                1  -none-     numeric\nNobs               1  -none-     numeric\nChisq              1  -none-     numeric\npredcell          11  data.frame list   \nGsq                1  -none-     numeric\ny                  9  data.frame list   \nx                  1  data.frame list   \nN                  1  -none-     numeric\nmaxiter            1  -none-     numeric\nresid.df           1  -none-     numeric\ntime               1  difftime   numeric\ncall               5  -none-     call   \n```\n\n\n:::\n:::\n\n\nEssentially, I'm grouping people into classes based on their security attitudes using the 9 items that I have.\nLet's check the 2 classes results.\nHow to interpret the results: \n\n* First, $Pr(1)$ is probability the person in class $x$ picks 1 for an item (1 here is the previous 0). So: \n\n> $SEC_RES_LOC\n> ------------\n> Pr(1), class 1: 0.68 \n> \n> Pr(2), class 2: 0.11\n\nMeans people in class 1 are more likely to not restrict their location (`SEC_RES_LOC = 0` has a higher chance in class 1). \nThis can just be people with high and low security tolerance. \nThe *Estimated class population shares* for classes are very close to the prediction of my model, i.e., *Predicted class memberships (by modal posterior prob.)*. \nThis means these are very good estimates. \nThe fit statistics shows: AIC, BIC, deviance, and $\\chi^2$.\n\nNow let's try for 2,3 and 4 classes and pick the best - using AIC/BIC (lower = better fit):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninvisible(capture.output({lca_2 <- poLCA(form, data = wrk_ds, nclass = 2)}))\ninvisible(capture.output({lca_3 <- poLCA(form, data = wrk_ds, nclass = 3)}))\ninvisible(capture.output({lca_4 <- poLCA(form, data = wrk_ds, nclass = 4)}))\n\n# Compare AIC and BIC\ndata.frame(\n  Classes = 2:4,\n  AIC = c(lca_2$aic, lca_3$aic, lca_4$aic),\n  BIC = c(lca_2$bic, lca_3$bic, lca_4$bic)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Classes      AIC      BIC\n1       2 187513.7 187662.4\n2       3 183851.6 184078.7\n3       4 180666.1 180971.4\n```\n\n\n:::\n:::\n\n\nThis is telling me PSEC should have 4 levels. \n\n**Step 7. Calculate Perceived Security**\n\nAnother way to define `PSEC` is to use Item Response Theory (1 parameter logistic model, Rasch Model). \nThis will give a continous value for `PSEC`, which is preferrable for my analysis. \nEach item shares the same slope and I estimate \n\n$$\nP(Y_{ij} = 1) = \\frac{1}{1 + e^{PSEC_j - b_i}}\n$$\n\nWhere $PSEC_j$ is person $j$'s perceived security and $b_i$ is item $i$'s threshold.\nThe idea is of $b_i$ is: how hard is it for someone to agree with something.\nSo, in my example, how high/low does the person's security perception have to be to skip setting up 2FA/set up 2FA. \n\n> Note: IF PSEC = b, then the person has a 50-50 chance of agreeing. \n\nBottom line:\n\n* If an item has high threshold, only those with high perceived security agree with it. \n* If an item has low thresholds, most agree with. \n\nSo, let's define `PSEC`:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run a 1-parameter logistic model (Rasch Model)\nirt_model <- mirt(wrk_ds[, c(\"SEC_RES_LOC\", \"SEC_RES_DAT\", \"SEC_ACC_WEBSEC\",\n                             \"SEC_ACC_CHNGPRV\", \"SECOPT_QS\", \"SECOPT_PL\",\n                             \"SECOPT_2FA\", \"SECOPT_BIO\", \"SECOPT_PAS\")], 1, itemtype=\"Rasch\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nIteration: 1, Log-Lik: -94814.100, Max-Change: 0.40153\nIteration: 2, Log-Lik: -93680.902, Max-Change: 0.41232\nIteration: 3, Log-Lik: -93047.348, Max-Change: 0.36846\nIteration: 4, Log-Lik: -92734.044, Max-Change: 0.29365\nIteration: 5, Log-Lik: -92591.472, Max-Change: 0.21441\nIteration: 6, Log-Lik: -92529.943, Max-Change: 0.14683\nIteration: 7, Log-Lik: -92504.107, Max-Change: 0.09617\nIteration: 8, Log-Lik: -92493.300, Max-Change: 0.06119\nIteration: 9, Log-Lik: -92488.690, Max-Change: 0.03822\nIteration: 10, Log-Lik: -92486.647, Max-Change: 0.02357\nIteration: 11, Log-Lik: -92485.693, Max-Change: 0.01445\nIteration: 12, Log-Lik: -92485.221, Max-Change: 0.00882\nIteration: 13, Log-Lik: -92484.970, Max-Change: 0.00567\nIteration: 14, Log-Lik: -92484.829, Max-Change: 0.00316\nIteration: 15, Log-Lik: -92484.756, Max-Change: 0.00192\nIteration: 16, Log-Lik: -92484.712, Max-Change: 0.00125\nIteration: 17, Log-Lik: -92484.685, Max-Change: 0.00070\nIteration: 18, Log-Lik: -92484.670, Max-Change: 0.00040\nIteration: 19, Log-Lik: -92484.661, Max-Change: 0.00028\nIteration: 20, Log-Lik: -92484.655, Max-Change: 0.00015\nIteration: 21, Log-Lik: -92484.652, Max-Change: 0.00009\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract person-level scores (PSEC)\nwrk_ds$PSEC <- fscores(irt_model)\n```\n:::\n\n\nThis is a 1-factor model (`PSEC`).\nWe find the factor scores (`fscores()`), otherwise known as latent trat scores, which estimate each person's position on the latent construct (basically, each person's `PSEC` score).\nScores are usually centered around 0, and the more negative values are lower scores. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(irt_model, simplify=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$items\n                a1      d g u\nSEC_RES_LOC      1  1.022 0 1\nSEC_RES_DAT      1  0.867 0 1\nSEC_ACC_WEBSEC   1 -0.348 0 1\nSEC_ACC_CHNGPRV  1  0.078 0 1\nSECOPT_QS        1  0.483 0 1\nSECOPT_PL        1 -1.113 0 1\nSECOPT_2FA       1  1.483 0 1\nSECOPT_BIO       1 -0.937 0 1\nSECOPT_PAS       1 -0.735 0 1\n\n$means\nF1 \n 0 \n\n$cov\n      F1\nF1 3.093\n```\n\n\n:::\n:::\n\n\nSummary statistics of `PSEC` values: \n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(wrk_ds$PSEC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       F1            \n Min.   :-2.8540382  \n 1st Qu.:-1.3479926  \n Median : 0.1676207  \n Mean   : 0.0009833  \n 3rd Qu.: 1.2059331  \n Max.   : 2.7349158  \n```\n\n\n:::\n:::\n\n\n\nSimilar to this, but much easier - since I already used `lavaan` to do CFA, you can just use the same package to calculate the `PSEC` values for users.\nThis is what I will use for the paper: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds$PSEC <- lavPredict(compatibility_fac)\nsummary(wrk_ds$PSEC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       f          \n Min.   :-1.5300  \n 1st Qu.:-0.7069  \n Median : 0.1029  \n Mean   : 0.0000  \n 3rd Qu.: 0.7779  \n Max.   : 1.3023  \n```\n\n\n:::\n:::\n\n\n\n## Build Datasets for Modeling \nSo, I need 3 different datasets for modeling: \n\n* Full Data: includes everything \n* PHON-only Data: only smartphone users \n* WEAR-only Data: only smartwear users \n\nLet's separate the data: \n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds <- wrk_ds %>% mutate(\n    isSmartPhone = if_else(\n        SMRTPHN == 1,\n        1,\n        0\n    ),\n    isSmartWear = if_else(\n        SMRTWTCH == 1,\n        1,\n        0\n    )\n)\n```\n:::\n\n\n\n### Some Visualizations \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(wrk_ds, aes(x = PSEC)) +\n  geom_histogram(binwidth = 0.5, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Perceived Security (PSEC) Scores\", \n       x = \"PSEC Score\", \n       y = \"Number of Users\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](study3_DA_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(aes(x = as.factor(isSmartWear), y = MBANK, color = as.factor(PRVNC)), data = wrk_ds) + \n    stat_summary(fun.data = \"mean_cl_boot\", geom = 'line', aes(group = as.factor(PRVNC))) +\n    labs(x = \"Wearable User\", y = \"Probability of M-banking\", color = \"Province\") + \n    scale_color_brewer(palette = \"Paired\") +\n    theme_minimal()\n\np2 <- ggplot(wrk_ds, aes(as.factor(PRVNC), MBANK, color = as.factor(isSmartWear))) +\n                  stat_summary(fun = mean, geom = \"point\") +\n                  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\", width = 0.4) +\n                  theme_set(theme_bw(base_size = 10)) +\n                  theme(legend.position = \"top\") +\n                  labs(x = \"Province\", y = \"Observed Probabilty of mobile banking\", color = \"Wearable User\") + theme_minimal()\n\nggarrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](study3_DA_files/figure-html/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n\nIt doesn't really looks like there's much grouping happening here! \nLet's build the datasets: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds <- wrk_ds %>% mutate(\n    scaled_wtpg = wtpg/max(wtpg)\n)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds_fulldata <- wrk_ds %>% mutate(\n    # if name has \"_f\" after it, it's a factor. \n    # if name has a \"_c\" after it, it's mean centered. \n    # if name has no trailing letter, it's just an integer (probably 0-1)\n    \n    PRVNC_f = as.factor(PRVNC),\n    SEX_f = factor(SEX,levels = c(\"0\", \"1\")), \n    \n    EDU_f = factor(EDU, levels = c(\"1\", \"2\", \"3\")), \n    EDU_c = EDU - mean(EDU),\n    \n    AGE_f = as.factor(AGE),\n    AGE_f = relevel(AGE_f, ref = \"2\"),\n    AGE_c = AGE - mean(AGE),\n\n    INCOME_f = as.factor(INCOME), \n    INCOME_c = INCOME - mean(INCOME),\n    \n    EFF_TIME_f = as.factor(EFF_TIME),\n    \n\n    # added variables \n    \n    PSEC_c1 = PSEC - min(PSEC) + 1,\n    PSEC_c = PSEC - mean(PSEC), \n    PSEC_scaled = 1 + 7 * ((PSEC - min(PSEC)) / (max(PSEC) - min(PSEC))),\n    \n    TRST_BANK_f = as.factor(TRST_BANK),\n    TRST_BANK_f = relevel(TRST_BANK_f, ref = \"5\"),\n    TRST_BANK_c = TRST_BANK - mean(TRST_BANK),\n    \n    USR_TYP = case_when(\n        isSmartWear == 1 ~ \"WEAR\",\n        isSmartWear == 0 ~ \"PHON\",\n        .default = \"OTHER\"\n        )\n    )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrk_ds_fulldata_PHON <- wrk_ds_fulldata %>% filter(isSmartWear == 0) \nwrk_ds_fulldata_WEAR <- wrk_ds_fulldata %>% filter(isSmartWear == 1) \n```\n:::\n\n\nLet's see the counts for the groups: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nctab <- table(wrk_ds_fulldata$MBANK, wrk_ds_fulldata$USR_TYP)\nctab\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   \n     PHON  WEAR\n  0  2214   169\n  1 13174  2995\n```\n\n\n:::\n:::\n\n\nA simple $\\chi^2$ test shows these users are significantly different in how they m-bank:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(ctab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  ctab\nX-squared = 191.04, df = 1, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\nSummary Statistics of the dataset: \n\n\n::: {.cell}\n\n```{.r .cell-code}\npsycDescribe <- psych::describe(\n    wrk_ds_fulldata %>% dplyr::select(isSmartWear, AGE, SEX, EDU, INCOME, EFF_TIME, TRST_BANK, PSEC) #if it's numeric.\n    ) \n\npsycDescribe <- as.data.frame(psycDescribe)\ngt(psycDescribe)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"yiwcbgqzgh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#yiwcbgqzgh table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#yiwcbgqzgh thead, #yiwcbgqzgh tbody, #yiwcbgqzgh tfoot, #yiwcbgqzgh tr, #yiwcbgqzgh td, #yiwcbgqzgh th {\n  border-style: none;\n}\n\n#yiwcbgqzgh p {\n  margin: 0;\n  padding: 0;\n}\n\n#yiwcbgqzgh .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#yiwcbgqzgh .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yiwcbgqzgh .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yiwcbgqzgh .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yiwcbgqzgh .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yiwcbgqzgh .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yiwcbgqzgh .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yiwcbgqzgh .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yiwcbgqzgh .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#yiwcbgqzgh .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#yiwcbgqzgh .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yiwcbgqzgh .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yiwcbgqzgh .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yiwcbgqzgh .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yiwcbgqzgh .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yiwcbgqzgh .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#yiwcbgqzgh .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#yiwcbgqzgh .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#yiwcbgqzgh .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yiwcbgqzgh .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#yiwcbgqzgh .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yiwcbgqzgh .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yiwcbgqzgh .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yiwcbgqzgh .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yiwcbgqzgh .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yiwcbgqzgh .gt_left {\n  text-align: left;\n}\n\n#yiwcbgqzgh .gt_center {\n  text-align: center;\n}\n\n#yiwcbgqzgh .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yiwcbgqzgh .gt_font_normal {\n  font-weight: normal;\n}\n\n#yiwcbgqzgh .gt_font_bold {\n  font-weight: bold;\n}\n\n#yiwcbgqzgh .gt_font_italic {\n  font-style: italic;\n}\n\n#yiwcbgqzgh .gt_super {\n  font-size: 65%;\n}\n\n#yiwcbgqzgh .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#yiwcbgqzgh .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#yiwcbgqzgh .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#yiwcbgqzgh .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#yiwcbgqzgh .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#yiwcbgqzgh .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#yiwcbgqzgh .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#yiwcbgqzgh .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#yiwcbgqzgh div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"vars\">vars</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"n\">n</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mean\">mean</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"sd\">sd</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"median\">median</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"trimmed\">trimmed</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"mad\">mad</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"min\">min</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"max\">max</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"range\">range</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"skew\">skew</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"kurtosis\">kurtosis</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"se\">se</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">1</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">1.705476e-01</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.3761234</td>\n<td headers=\"median\" class=\"gt_row gt_right\">0.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">0.08819566</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"min\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">1.75173699</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">1.0686401</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.002761436</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">2</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">4.117400e+00</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">1.5025952</td>\n<td headers=\"median\" class=\"gt_row gt_right\">4.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">4.20165746</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">1.482600</td>\n<td headers=\"min\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">6.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">5.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.31941695</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.0076646</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.011031806</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">3</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">5.211837e-01</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.4995645</td>\n<td headers=\"median\" class=\"gt_row gt_right\">1.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">0.52647891</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"min\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.08480409</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.9929157</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.003667720</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">4</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">2.151951e+00</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.7866826</td>\n<td headers=\"median\" class=\"gt_row gt_right\">2.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">2.18993397</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">1.482600</td>\n<td headers=\"min\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">3.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">2.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.27452999</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.3370776</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.005775694</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">5</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">3.230972e+00</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">1.3482437</td>\n<td headers=\"median\" class=\"gt_row gt_right\">3.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">3.28870772</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">1.482600</td>\n<td headers=\"min\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">5.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">4.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.19217593</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.1623489</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.009898583</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">6</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">5.085705e-01</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.4999400</td>\n<td headers=\"median\" class=\"gt_row gt_right\">1.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">0.51071284</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"min\" class=\"gt_row gt_right\">0.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.03428428</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.9989323</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.003670477</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">7</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">3.710921e+00</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.9637567</td>\n<td headers=\"median\" class=\"gt_row gt_right\">4.0000000</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">3.80083547</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">1.482600</td>\n<td headers=\"min\" class=\"gt_row gt_right\">1.000000</td>\n<td headers=\"max\" class=\"gt_row gt_right\">5.000000</td>\n<td headers=\"range\" class=\"gt_row gt_right\">4.000000</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.68270585</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">0.3415415</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.007075743</td></tr>\n    <tr><td headers=\"vars\" class=\"gt_row gt_right\">8</td>\n<td headers=\"n\" class=\"gt_row gt_right\">18552</td>\n<td headers=\"mean\" class=\"gt_row gt_right\">2.573285e-17</td>\n<td headers=\"sd\" class=\"gt_row gt_right\">0.8816774</td>\n<td headers=\"median\" class=\"gt_row gt_right\">0.1028678</td>\n<td headers=\"trimmed\" class=\"gt_row gt_right\">0.03752289</td>\n<td headers=\"mad\" class=\"gt_row gt_right\">1.053947</td>\n<td headers=\"min\" class=\"gt_row gt_right\">-1.529966</td>\n<td headers=\"max\" class=\"gt_row gt_right\">1.302335</td>\n<td headers=\"range\" class=\"gt_row gt_right\">2.832302</td>\n<td headers=\"skew\" class=\"gt_row gt_right\">-0.30718042</td>\n<td headers=\"kurtosis\" class=\"gt_row gt_right\">-1.0974666</td>\n<td headers=\"se\" class=\"gt_row gt_right\">0.006473130</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n## Modeling \n\nFirst, since there's clustering on provinces, I run a fixed effect model and test it against a simple logistic regression to see if there is a grouping effect. \nFirst of all, the model fails to converge - \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_full_fixedeffect <- glmer(\n    MBANK ~ AGE_f + SEX_f + EDU_f + INCOME_f + EFF_TIME_f + TRST_BANK_f + PSEC + (1 | PRVNC),\n    data = wrk_ds_fulldata,\n    family = binomial,\n    weights = scaled_wtpg\n)\n```\n:::\n\n\n\n> Warning :non-integer #successes in a binomial glm!\n> \n> Warning :failure to converge in 10000 evaluations\n> \n> Warning :convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations\n> \n> Warning :unable to evaluate scaled gradient\n> \n> Warning :Model failed to converge: degenerate  Hessian with 1 negative eigenvalues\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_full <- glm(\n    MBANK ~ AGE_f + SEX_f + EDU_f + INCOME_f + EFF_TIME_f + TRST_BANK_f + PSEC,\n    data = wrk_ds_fulldata,\n    family = quasibinomial,\n    weights = scaled_wtpg\n)\n```\n:::\n\n\nThe LR test shows that there is no improvement to the model, so going with the simpler model is better. \n\n::: {.cell}\n\n```{.r .cell-code}\nlrtest(model_full, model_full_fixedeffect)\n```\n:::\n\n\n|#DF|LogLik|Df|Chisq|Pr(>Chisq)|\n|---|------|--|-----|----------|\n|19|||||\n|20|-27.041|1|||\n\nThe mathematical formulations of all three models follows this: \n\n$$\n\\begin{equation*}\n    \\begin{split}\n        & logit(MBANK) = \\\\\n        & \\hspace{1cm} \\beta_0 + \n        \\beta_1 \\ AGE_1 \\ +\n        \\beta_2 \\ AGE_3 \\ +\n        \\beta_3 \\ AGE_4 \\ +\n        \\beta_4 \\ AGE_5 \\ +\n        \\beta_5 \\ AGE_6 \\ + \\\\\n        & \\hspace{1cm} \\beta_6 \\ SEX_F \\ +\n        \\beta_7 \\ EDU_2 \\ + \n        \\beta_8 \\ EDU_3 \\ + \n        \\beta_{9} \\ INCOME_2 \\ + \n        \\beta_{10} \\ INCOME_3 \\ + \\\\\n        & \\hspace{1cm} \\beta_{11} \\ INCOME_4 \\ +\n        \\beta_{12} \\ INCOME_5 \\ + \n        \\beta_{13} \\ EFF\\_TIME \\ +\n        \\beta_{14} \\ TRST\\_BANK_1 \\ + \\\\\n        & \\hspace{1cm} \\beta_{15} \\ TRST\\_BANK_2 \\ + \n        \\beta_{16} \\ TRST\\_BANK_3 \\ + \n        \\beta_{17} \\ TRST\\_BANK_4 \\ + \n        \\beta_{18} \\ PSEC \\ + \\epsilon \\\\ \n    \\end{split}\n\\end{equation*}\n$$\n\nThe only difference is the dataset each is coming from. \nI do need to calculate the robust cluster standard errors for more accurate results: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_full_cluster_se <- vcovCL(model_full, cluster = wrk_ds_fulldata$PRVNC)\n\n# summary table of results \nmodel_full_summary_clustered <- coeftest(model_full, vcov = model_full_cluster_se)\n\n\n# PHON-only \nmodel_phon <- glm(\n    MBANK ~ AGE_f + SEX_f + EDU_f + INCOME_f + EFF_TIME_f + TRST_BANK_f + PSEC,\n    data = wrk_ds_fulldata_PHON,\n    family = quasibinomial,\n    weights = scaled_wtpg\n)\n\nmodel_phon_cluster_se <- vcovCL(model_phon, cluster = wrk_ds_fulldata_PHON$PRVNC)\nmodel_phon_summary_clustered <- coeftest(model_phon, vcov = model_phon_cluster_se)\n\n\n# WEAR-only\nmodel_wear <- glm(\n    MBANK ~ AGE_f + SEX_f + EDU_f + INCOME_f + EFF_TIME_f + TRST_BANK_f + PSEC,\n    data = wrk_ds_fulldata_WEAR,\n    family = quasibinomial,\n    weights = scaled_wtpg\n)\n\nmodel_wear_cluster_se <- vcovCL(model_wear, cluster = wrk_ds_fulldata_WEAR$PRVNC)\nmodel_wear_summary_clustered <- coeftest(model_wear, vcov = model_wear_cluster_se)\n```\n:::\n\n\n\nUsing textreg (in my original R markdown file, and htmlreg here for website preview) to produce $\\LaTeX$ code for the table: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nscreenreg(\n  list(model_full_summary_clustered, model_phon_summary_clustered, model_wear_summary_clustered),\n  custom.model.names = c(\"Full Data (coeff)\", \n                         \"Phone Only (coeff)\", \n                         \"WEAR Only (coeff)\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n======================================================================\n              Full Data (coeff)  Phone Only (coeff)  WEAR Only (coeff)\n----------------------------------------------------------------------\n(Intercept)    1.83 ***           1.95 ***            1.23 **         \n              (0.16)             (0.20)              (0.39)           \nAGE_f1        -1.01 ***          -1.12 ***           -0.25            \n              (0.05)             (0.11)              (0.25)           \nAGE_f3         0.02              -0.06                0.52 **         \n              (0.10)             (0.12)              (0.16)           \nAGE_f4        -0.03              -0.12                1.00            \n              (0.13)             (0.18)              (0.52)           \nAGE_f5        -0.09              -0.13                0.16            \n              (0.17)             (0.20)              (0.30)           \nAGE_f6        -0.23              -0.29                0.39            \n              (0.13)             (0.15)              (0.35)           \nSEX_f1         0.11 **            0.09 ***            0.16            \n              (0.03)             (0.02)              (0.27)           \nEDU_f2         0.32 ***           0.25 ***            1.02 ***        \n              (0.07)             (0.05)              (0.29)           \nEDU_f3         0.47 ***           0.42 ***            0.94 ***        \n              (0.02)             (0.03)              (0.22)           \nINCOME_f2      0.15 *             0.20 *             -0.51            \n              (0.07)             (0.09)              (0.35)           \nINCOME_f3      0.20 *             0.21 *             -0.03            \n              (0.09)             (0.10)              (0.28)           \nINCOME_f4      0.43 ***           0.42 ***            0.19            \n              (0.12)             (0.12)              (0.42)           \nINCOME_f5      0.59 ***           0.60 ***            0.16            \n              (0.10)             (0.15)              (0.44)           \nEFF_TIME_f1    0.56 ***           0.54 ***            0.69 *          \n              (0.05)             (0.04)              (0.33)           \nTRST_BANK_f1  -1.44 ***          -1.53 ***           -0.00            \n              (0.18)             (0.17)              (0.59)           \nTRST_BANK_f2  -0.69 ***          -0.67 ***           -0.66 ***        \n              (0.17)             (0.18)              (0.19)           \nTRST_BANK_f3  -0.67 ***          -0.73 ***           -0.29            \n              (0.13)             (0.12)              (0.19)           \nTRST_BANK_f4  -0.11              -0.16                0.31            \n              (0.12)             (0.09)              (0.40)           \nPSEC           0.93 ***           0.94 ***            0.70 ***        \n              (0.05)             (0.04)              (0.09)           \n======================================================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\n```\n\n\n:::\n:::\n\n\nThe R code to generate $\\LaTeX$ code: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntexreg(\n  list(model_full_summary_clustered, \n       model_phon_summary_clustered, \n       model_wear_summary_clustered),\n  custom.model.names = c(\"Full Data\", \"Phone-Only\", \"Wear-Only\"), \n  digits = 3,              \n  stars = c(0.001, 0.01, 0.05), # Significance levels for stars\n  single.row = FALSE, # Standard errors in parentheses below coefficients\n  custom.note = \"Significance levels: *p < 0.05; **p < 0.01; ***p < 0.001\", \n  booktabs = TRUE,   # Use booktabs-style formatting\n  caption = \"Logistic Regression Results with Robust Standard Errors\"\n)\n```\n:::\n\n\n## Analysis of Results \nSince the point it to compare the values for coefficients in each model, I will need to perform wald test. \nIt's essentially just a Z statistic calculation. \nLet's consider $\\hat{\\beta_{p1}}$ the estimated coefficient of variable 1 from the PHON only model and $\\hat{beta_{w1}}$ the same variable's estimate coefficient in WEAR only model. \nI want to know, is the difference between the two significantly different from zero? \nThat is, $H_0: \\hat{\\beta_{p1}} - \\hat{\\beta_{w1}} = 0$.\nIf I reject $H_0$, that means they're significantly different. \nThe statistic is calculated as the ratio of the estimate (difference) over the standard error the estimate (difference): \n$$\nZ = \\frac{\\hat{\\beta_{p1}} - \\hat{\\beta_{w1}}}{\\sqrt{\\sigma_{\\beta_{p1}} + \\sigma_{\\beta_{w1}}}}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_wald_test <- function(model1, model2, variable_name){\n    coeff1 <- model1[variable_name, 1]\n    coeff2 <- model2[variable_name, 1]\n    \n    se1 <- model1[variable_name, 2]\n    se2 <- model1[variable_name, 2]\n    \n    diff <- coeff1 - coeff2\n    se_diff <- sqrt(se1^2 + se2^2)\n    z <- diff / se_diff\n    p <- 2 * (1 - pnorm(abs(z)))\n    res <- c(z = z, p = p)\n\n    return(res)\n}\n```\n:::\n\n\nHere's how you do this: \n\n* Get the results for FullData vs PHON\n* Get the results for FullData vs WEAR\n* Get the results for PHON vs WEAR\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs_ <- c('AGE_f1', 'AGE_f3','AGE_f4','AGE_f5','AGE_f6',\n            'SEX_f1',\n            'EDU_f2','EDU_f3',\n            'INCOME_f2','INCOME_f3','INCOME_f4','INCOME_f5',\n            'EFF_TIME_f1', \n            'TRST_BANK_f1','TRST_BANK_f2','TRST_BANK_f3','TRST_BANK_f4',\n            'PSEC')\n    \n\nresults <- c()\n\n# Loop through coefficients and format results\nfor (coef_ in coefs_) {\n\n    full_vs_phone <- calc_wald_test(model_full_summary_clustered, model_phon_summary_clustered, coef_)\n    full_vs_wear <- calc_wald_test(model_full_summary_clustered, model_wear_summary_clustered, coef_)\n    phone_vs_wear <- calc_wald_test(model_phon_summary_clustered, model_wear_summary_clustered, coef_)\n    \n  ## Check significance (if p > 0.05, set as \"no\", otherwise keep z-score)\n  # the dollar signs and ^{} are because I wanted to copy paste the results into LaTeX overleaf ! IGNORE \n    full_vs_phone_text <- paste0(\"$ \", round(full_vs_phone[\"z\"], 3), \"^{} $ & \", \" $ \", round(full_vs_phone[\"p\"], 3), \"$\")\n    full_vs_wear_text <- paste0(\"$ \", round(full_vs_wear[\"z\"], 3), \"^{} $ & \", \" $ \", round(full_vs_wear[\"p\"], 3), \"$\")\n    phone_vs_wear_text <- paste0(\"$ \", round(phone_vs_wear[\"z\"], 3), \"^{} $ & \", \" $ \", round(phone_vs_wear[\"p\"], 3), \"$\")\n\n         \n  # Format the result for this coefficient\n  # again, the &'s are for overleaf / LaTeX convenience \n  result <- paste0(\n    full_vs_phone_text, \" & \",\n    full_vs_wear_text, \" & \",\n    phone_vs_wear_text\n    )\n  \n  # Append to results list\n  results <- c(results, result)\n}\n\n\n# Print the results\nfor (res in results) {\n  print(res)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"$ 1.485^{} $ &  $ 0.137$ & $ -10.352^{} $ &  $ 0$ & $ -5.625^{} $ &  $ 0$\"\n[1] \"$ 0.555^{} $ &  $ 0.579$ & $ -3.413^{} $ &  $ 0.001$ & $ -3.48^{} $ &  $ 0.001$\"\n[1] \"$ 0.46^{} $ &  $ 0.646$ & $ -5.48^{} $ &  $ 0$ & $ -4.488^{} $ &  $ 0$\"\n[1] \"$ 0.142^{} $ &  $ 0.887$ & $ -1.072^{} $ &  $ 0.284$ & $ -1.038^{} $ &  $ 0.299$\"\n[1] \"$ 0.33^{} $ &  $ 0.742$ & $ -3.488^{} $ &  $ 0$ & $ -3.159^{} $ &  $ 0.002$\"\n[1] \"$ 0.493^{} $ &  $ 0.622$ & $ -1.138^{} $ &  $ 0.255$ & $ -2.363^{} $ &  $ 0.018$\"\n[1] \"$ 0.698^{} $ &  $ 0.485$ & $ -6.641^{} $ &  $ 0$ & $ -10.406^{} $ &  $ 0$\"\n[1] \"$ 1.5^{} $ &  $ 0.134$ & $ -13.742^{} $ &  $ 0$ & $ -12.788^{} $ &  $ 0$\"\n[1] \"$ -0.525^{} $ &  $ 0.6$ & $ 6.484^{} $ &  $ 0$ & $ 5.403^{} $ &  $ 0$\"\n[1] \"$ -0.069^{} $ &  $ 0.945$ & $ 1.932^{} $ &  $ 0.053$ & $ 1.658^{} $ &  $ 0.097$\"\n[1] \"$ 0.071^{} $ &  $ 0.943$ & $ 1.456^{} $ &  $ 0.145$ & $ 1.351^{} $ &  $ 0.177$\"\n[1] \"$ -0.063^{} $ &  $ 0.95$ & $ 3.013^{} $ &  $ 0.003$ & $ 2.13^{} $ &  $ 0.033$\"\n[1] \"$ 0.382^{} $ &  $ 0.702$ & $ -1.923^{} $ &  $ 0.054$ & $ -2.489^{} $ &  $ 0.013$\"\n[1] \"$ 0.361^{} $ &  $ 0.718$ & $ -5.769^{} $ &  $ 0$ & $ -6.453^{} $ &  $ 0$\"\n[1] \"$ -0.071^{} $ &  $ 0.943$ & $ -0.141^{} $ &  $ 0.888$ & $ -0.065^{} $ &  $ 0.948$\"\n[1] \"$ 0.287^{} $ &  $ 0.774$ & $ -2.181^{} $ &  $ 0.029$ & $ -2.682^{} $ &  $ 0.007$\"\n[1] \"$ 0.301^{} $ &  $ 0.763$ & $ -2.475^{} $ &  $ 0.013$ & $ -3.559^{} $ &  $ 0$\"\n[1] \"$ -0.19^{} $ &  $ 0.849$ & $ 3.546^{} $ &  $ 0$ & $ 4.524^{} $ &  $ 0$\"\n```\n\n\n:::\n:::\n\n\n## Bonus Visualizations \n\n\n::: {.cell}\n\n```{.r .cell-code}\nage_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(AGE_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = relevel(AGE_f, ref = \"1\"), y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"AGE Group\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\nsex_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(SEX_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = relevel(SEX_f, ref = \"1\"), y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"Gender\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\n\n\nedu_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(EDU_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = EDU_f, y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"Education\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\ntrst_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(TRST_BANK_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = relevel(TRST_BANK_f, ref = \"1\"), y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"Trust in Bank\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\nsec_gg <- ggplot(wrk_ds_fulldata %>%\n           mutate(PSECBIN = cut(PSEC, breaks = 7)) %>% \n           group_by(PSECBIN, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = PSECBIN, y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 2, alpha = 0.6) +  \n  labs(\n    x = \"PSEC (Binned)\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\", angle = 45, hjust = 1))\n\nincome_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(INCOME_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = INCOME_f, y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"Income\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\neff_gg <- ggplot(wrk_ds_fulldata %>%\n           group_by(EFF_TIME_f, USR_TYP) %>%\n           mutate(Proportion_mbank = mean(MBANK)), \n       aes(x = EFF_TIME_f, y = Proportion_mbank, color = USR_TYP, group = USR_TYP, linetype = USR_TYP)) +\n  geom_line(size = 1) +  \n  geom_point(size = 3) +  \n  labs(\n    x = \"EFF_TIME\",\n    y = \"Proportion MBANK\",\n    color = \"User Type\"\n  ) +\n  theme_minimal() + theme(strip.text = element_text(size = 12, face = \"bold\"), axis.text.x = element_text(face = \"bold\"))\n\n\n\nggarrange(age_gg, sex_gg, edu_gg, income_gg, eff_gg, trst_gg, sec_gg,\n          ncol = 4, nrow = 2) \n```\n\n::: {.cell-output-display}\n![](study3_DA_files/figure-html/unnamed-chunk-43-1.png){width=1440}\n:::\n:::\n\n\n\n\n",
    "supporting": [
      "study3_DA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}